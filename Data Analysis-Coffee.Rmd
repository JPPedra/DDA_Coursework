---
title: "CS5811-Data Distributed Analysis-Data Analysis on Arabica Coffee Beans"
author: "Hawra Nawrozzadeh, Joao Pedro Azevedo, and Roberta Sammarco"
date: "10/02/2022"
output: html_document
---

# 1. Introduction
This R Markdown report is a data analysis of the dataset on Arabica coffee beans that was extracted from the Coffee Quality Institute. The aim of this report is to perform a supervised machine learning and a high performance computational technique to answer the following research question: ......
In order to achieve this, the first stage is to preform data cleaning and preparation in order to optimise the dataset and to ensure the quality of the dataset is accurate, consistent, and reliable. "Measuring and checking the quality of the data identifies potential errors, that should be resolved appropriately, to prevent misleading results and conclusions" 
Exploratory Data Analysis (EDA) will then be preformed in order to .....
---- 
The metadata
Quality Measures
Aroma
Flavor
Aftertaste
Acidity
Body
Balance
Uniformity
Cup Cleanliness
Sweetness
Moisture
Defects
Bean Metadata
Processing Method
Color
Species (arabica / robusta)
Farm Metadata
Owner
Country of Origin
Farm Name
Lot Number
Mill
Company
Altitude
Region


# 2. Loading the Libraries

```{r}
library(dplyr)
library(validate)
```

# 3. Data Cleaning and Preparation

## 3.1 Loading the data 

```{r}
coffee <- read.csv("data/Coffee-modified.csv")
```

## 3.2 Data Qaulity Check (or something like this)

```{r}
str(coffee)
summary(coffee)
```
-From the summary and str .... function, it seems R has processed the dataset with  35 attributes categorical variables and the rest of the 9 attributes to be numerical continuous.
- However, this seems to be incorrect format because the in correct datatype..... e.g. ID and bla bla should be integer instead ...
- Additionally, we can already identify errors such as missing data and possible outliers (from looking at the ranges)...

- Lets further look into the different levels by creating an object that converts the strings into a factor. By doing this, we can also see other details that we will help us to decide which attributes are redundant or irrelavent for our research question.

Let's further investigate this and see if R interpreted these data types correctly
```{r}
coffee_fac_lev <- read.csv("data/Coffee-modified.csv", stringsAsFactors = T)
str(coffee_fac_lev)
summary(coffee_fac_lev)
```

as (function) shows, there is extremely huge amount of redundant attribute such as .... , ...., that 

-- maybe this is where we use the validate package

- having a look at the str and the summary as well as the validate package shows that there is a lot of missing instances,....., ...., there we will keep bla bla to help us in invesitgation our research question better without having redundant info affecting our results.
- gives examples of why it is not good have to many missing NAs and outliers.....

```{r}
sapply(coffee, table)
sapply(head(table(coffee$ID), 20))

head(sapply(coffee, table), 20)

coffee_1<- coffee
coffee_1<- as.integer(coffee_1$Altitude)
is.na(coffee_1$Altitude)

any(is.na(coffee_1))

coffee_1[which(coffee_1 == " "), c(10)]

sum(!complete.cases(coffee$Altitude))

sum(coffee$Altitude=="")
sum(coffee$Country.of.Origin=="")
View(table(coffee$Country.of.Origin))
sum(coffee$Processing.Method=="")
View(table(coffee$Processing.Method))
```



As a results, in order to answer our research, we would only need the following variables....

à	ID
à	Owner
à	Farm Name
à	Lot Number
à	Mill 
à	ICO Number
à	Company
à	Region
à	Producer
à	In country Partner
à	Harvest Year
à	Owner 1
à	Expiration
à	Certification Body
à	certification address 
à	Certification number
à	Unit of measurements

```{r}
colnames(coffee)
coffee %>%
  select(-c("ID", "Owner", "Farm.Name", "Lot.Number", "Mill", ""))

# football_num <- football %>%
#   select(-c("sofifa_id", "club_name", "preferred_foot"))
# 
# coffee_new <- coffee[ ,c(1, 2, 4, 10, 13, 14, 17, 19:32, 34, 42:44)]


```

```{r}

```




- look out for duplicates
- look out for outliers
- look out for missing data <- imputation
- visualize and show the improvements made

# 4. Exploratory Data Analysis












